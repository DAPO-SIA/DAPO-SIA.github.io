<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="DAPO: An Open-Source State-of-The-Art LLM Reinforcement Learning System"> <!-- TODO: add some description, visible outside -->
  <meta name="keywords" content="DAPO, Deepseek-R1, PPO, GRPO, AIME, SIA-Lab, Tsinghua University, ByteDance AlphaSeed"> <!-- TODO: add some keywords for search engine -->
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>DAPO</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome_6_7_2.all.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome_6_7_2.all.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <!-- <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a> -->

      <!-- <div class="navbar-item has-dropdown is-hoverable"> -->
        <!-- <a class="navbar-link">
          More Research
        </a> -->
        <!-- <div class="navbar-dropdown"> -->
          <!-- <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a> -->
        <!-- </div> -->
      <!-- </div> -->
    <!-- </div> -->

  <!-- </div> -->
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">
            DAPO: An Open-Source State-of-The-Art LLM Reinforcement Learning System
          </h1> <!-- TODO: fix the title -->
          <!-- <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="">Author 1</a><sup>1,2,3</sup>,</span>
            <span class="author-block">
              <a href="">Author 2</a><sup>1,2,3</sup>,</span>
            <span class="author-block">
              <a href="">Author 3</a><sup>1,2,3</sup>,
            </span>
          </div> -->

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>ByteDance Seed</span>
            &nbsp;
            <span class="author-block"><sup>2</sup>Institute for AI Industry Research (AIR), Tsinghua University</span>
            <span class="author-block"><sup>3</sup>The University of Hong Kong</span>
            <br>
            <span class="author-block"><sup>4</sup>SIA-Lab of Tsinghua AIR and ByteDance Seed</span>
          </div>
          <div class="is-size-6 publication-authors">
            <span class="author-block">*Full author list in Contributions</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="./static/pdf/dapo_paper.pdf"
                   class="external-link button is-normal is-rounded is-dark"> <!-- TODO: fix pdf link -->
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Arxiv Link. -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/BytedTsinghua-SIA/DAPO"
                   class="external-link button is-normal is-rounded is-dark"> <!-- TODO: fix repo link -->
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/BytedTsinghua-SIA/DAPO-Math-17k"
                   class="external-link button is-normal is-rounded is-dark"> <!-- TODO: fix dataset link -->
                  <span class="icon">
                      <i class="fa-regular fa-database"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span>
              <!-- Model Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark"> <!-- TODO: fix model link -->
                  <span class="icon">
                    <i class="fa-solid fa-face-smiling-hands"></i>
                  </span>
                  <span>Model (Coming Soon)</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser -->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="subtitle has-text-centered">
        <img src="static/images/puffin.png"/>
        <span class="dnerf">Puffin-Zero</span> is an open reasoning language model that demonstrates the potential of
        large-scale RL training from pretrained checkpoints on solving competition-level math problems.
      </h2>
      <h2 class="subtitle has-text-centered">
        <img src="static/images/score.png"/>
        <span class="dnerf">Puffin-Zero</span> achieves 45.4 points on AIME 2024, a comparable performance to DeepSeek-R1-Zero-
        Qwen-32B.
      </h2>
    </div>
  </div>
</section> -->

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We release a fully open-sourced system for large-scale LLM RL, including algorithm, code infrastructure, and dataset. The system achieves state-of-the-art large-scale LLM RL performance (AIME 50 on Qwen-32B pretrained model). We propose the Decoupled Clip and Dynamic SAmpling Policy Optimization (DAPO) algorithm. Through open-sourcing, we provide the broader research community and society with practical access to scalable reinforcement learning, enabling all to benefit from these advancements. Our system is based on the awesome <a href="https://github.com/volcengine/verl">verl</a> framework. Thanks for their great work!
          </p>
        </div>
      </div>
    </div>

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Key Result -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Key Results</h2>
        <div class="content has-text-justified">
          <p>
            We highlight the key results, focusing on the validation performance and training dynamics during DAPO training.
          </p>
          <p>
            Applying DAPO training to Qwen2.5-32B base model proves to outperform the previous state-of-the-art DeepSeek-R1-Zero-Qwen-32B on AIME24, with 50% less training steps. 
          </p>
          <p>
            In reinforcement learning for reasoning models, key metrics include response length, reward, entropy, and mean probability. Response length allows for complex reasoning but may fluctuate during training. Reward increases steadily but may not correlate with validation accuracy. Entropy measures exploration, and it is crucial to maintain a balanced level: too low limits exploration, too high causes randomness. Techniques like Clip-Higher prevents entropy collapse, and gradual entropy growth boosts performance. Mean probability indicates token sampling behavior, helping to balance exploration and exploitation.
          </p>
          </div>
      </div>
    </div>

    <!-- Score -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="subtitle has-text-centered">
          <img src="./static/images/score.png"/>
        </h2>
        AIME24 Performance
      </div>
    </div>

    <!-- Length -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="subtitle has-text-centered">
          <img src="./static/images/dynamics.png" />
        </h2>
        Training Dynamics
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Fully Open-Source -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Fully Open-Source</h2>
        <div class="content has-text-justified">
          <p>
            To benefit the broader research community, we make fully open-source the recipe of our RL training, including algorithm details, datasets, verifier, model weights and infrastructures. We hope our project could help the research community to unlock the secret of large-scale RL training much easier. We'll provide a detailed technical report soon.
          </p>
          <h3 class="title is-4">Infrastructure</h3>
          <p>
            We utilize <a href="https://github.com/volcengine/verl">verl</a> to perform DAPO training using the Qwen-32B-Base model from scratch with 128 H20 GPUs.
          </p>
          <h3 class="title is-4">Datasets</h3>
          <p>
            We provide training and validation datasets for DAPO training.
            <ul>
              <li>
                Training: <a href="https://huggingface.co/datasets/BytedTsinghua-SIA/DAPO-Math-17k">DAPO-Math-17k</a>, an elaborately curated math dataset. 
              </li>
              <li>
                Validation: <a href="https://huggingface.co/datasets/BytedTsinghua-SIA/AIME-2024">AIME 2024</a> dataset.
              </li>
            </ul>
          </p>
          <h3 class="title is-4">Verifiers</h3>
          <p>
            We adopt a simple but robust <a href="https://github.com/volcengine/verl/blob/gm-tyx/puffin/main/verl/utils/reward_score/math_dapo.py">rule-based verifier</a> relying on string normalization and matching.
          </p>
          <h3 class="title is-4">Training Scripts</h3>
          <p>
            We provide <a href="https://github.com/volcengine/verl/blob/gm-tyx/puffin/main/recipe/dapo/run_dapo_qwen2.5_32b.sh">the out-of-the-box script</a> for DAPO training reproduction.
          </p>
          <h3 class="title is-4">Model Weights</h3>
          <p>
            Coming Soon (training still in progress). Currently, the best evaluation accuracy for AIME24 is 50%.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Algorithm Insights -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Algorithm Insights</h2>
        <div class="content has-text-justified">
          <p>
            We propose the Decoupled Clip and Dynamic SAmpling Policy Optimization (DAPO) algorithm, which includes several key techniques as below. Detailed analysis and insights can be found in our technical report.
          </p>
          <ul>
            <li>
              Clip-Higher, which promotes the diversity of the system and avoids entropy collapse;
            </li>
          </ul>
          <p>
            We observe an entropy-collapsing phenomenon in our initial experiments. We propose increasing the upper clip range of the importance sampling ratio in policy gradient loss to mitigate this problem.
          </p>
          <ul>
            <li>
              Dynamic Sampling, which improves training efficiency and stability;
            </li>
          </ul>
          <p>
            We propose a strategy that performs dynamic sampling and filters out prompt groups with the accuracy equal to 1 and 0, keeping a consistent number of prompts with effective gradients across batches.
          </p>
          <ul>
            <li>
              Token-level Policy Gradient Loss, which is critical in long-CoT RL scenarios;
            </li>
          </ul>
          <ul>
            <li>
              Overlong Reward Shaping, which reduces reward noise and stabilizes training.
            </li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Datasets -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Dataset</h2>
        <div class="content has-text-justified">
          <p>
            The answers of math dataset typically come in a variety of formats, such as expression, formula and number, which makes it challenging to design comprehensive rules to parse them. To provide accurate reward signals using rules and minimize errors introduced by formula parsers, inspired by AIME, we select and transform the answers into integers, which are easy to parse. For example, if the original answer is expressed in the form of \( \frac{a + \sqrt{b}}{c} \), we instruct the LLM to modify the question so that the expected answer becomes \( a + b + c \). After selection and transformation, we obtained the DAPO-Math-17k dataset, which consists of 17k prompts, each paired with an integer as the answer.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Experiment Setting -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Experiment Setting</h2>
        <div class="content has-text-justified">
          <p>
            We utilize our training data to perform DAPO training on Qwen2.5-32B-Base without any cold start (i.e., supervised finetune). The model is trained on 16 H20 machines (128 H20 GPUs in total). Each machine is equipped with 8 NVIDIA H20-96GB GPUs inter-connected with 960 GB/s NVLink. The inter-machine bandwidth is 1200Gbps. We adopt <a href="https://github.com/volcengine/verl">verl</a> as the training framework. Our open-sourced experiments were conducted on the Volcano Engine Machine Learning Platform (<a href="https://console.volcengine.com/ml-platform">console</a>, 
    <a href="https://www.volcengine.com/docs/6459/">documentation</a>). 
    We will provide a full reproduction guideline on the Volcano Engine platform 
    to help users replicate our experiments.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Contributions -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Contributions</h2>
        <div class="content has-text-justified">
          <p>
            
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>
        <div class="content has-text-justified">
          
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2> <!-- TODO -->
    <pre><code>@article{2025puffinzero,
  author    = {Author 1, Author 2, Author 3},
  title     = {Puffin-Zero},
  journal   = {Arxiv},
  year      = {2025},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/pdf/dapo_paper.pdf"> <!-- TODO: fix pdf link -->
        <i class="fas fa-file-pdf"></i>
      </a>
      <!-- <a class="icon-link" href="" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a> -->
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is adapted from <a href="https://nerfies.github.io/">Nerfies</a> and licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
