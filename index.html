<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Democratizing LLM Reasoning
        by Unveiling the Secrets of RL Scaling"> <!-- TODO: add some description, visible outside -->
  <meta name="keywords" content="Puffin-Zero, Deepseek-R1, GRPO, AIME, SIA-Lab, Tsinghua University, ByteDance AlphaSeed"> <!-- TODO: add some keywords for search engine -->
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-site-verification" content="kprAnuq7DikheNqF213Uz7EMDHcgE-ivGPsTVfGzAsI" />
  <title>Puffin-Zero</title> <!-- TODO: fix the title displayed on top -->

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <!-- <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
  <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            processEscapes: true
        }
      });
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome_6_7_2.all.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/icon_3.png"> <!-- TODO: fix icon -->
  <link rel="shortcut icon" href="./static/images/icon_3.png"> <!-- TODO: fix icon -->
  <link rel="apple-touch-icon" href="./static/images/icon_3.png"> <!-- TODO: fix icon -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome_6_7_2.all.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href=""> <!-- TODO: add home link -->
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <!-- <div class="navbar-item has-dropdown is-hoverable"> -->
        <!-- <a class="navbar-link">
          More Research
        </a> -->
        <!-- <div class="navbar-dropdown"> -->
          <!-- <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a> -->
        <!-- </div> -->
      <!-- </div> -->
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">
            <img src="static/images/icon_3.png" style="width:1.25em;vertical-align: middle" alt="Logo" />
            <span class="dnerf">Puffin-Zero</span>: Democratizing LLM Reasoning
            by Unveiling the Secrets of RL Scaling
          </h1> <!-- TODO: fix the title -->
          <!-- <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="">Author 1</a><sup>1,2,3</sup>,</span>
            <span class="author-block">
              <a href="">Author 2</a><sup>1,2,3</sup>,</span>
            <span class="author-block">
              <a href="">Author 3</a><sup>1,2,3</sup>,
            </span>
          </div> -->

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>ByteDance Seed,</span>
            <span class="author-block"><sup>2</sup>Institute for AI Industry Research (AIR), Tsinghua University</span>
            <span class="author-block"><sup>3</sup>Tsinghua-ByteDance SIA-Lab</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">*Full author list in Contributions</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark"> <!-- TODO: fix pdf link -->
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Arxiv Link. -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark"> <!-- TODO: fix repo link -->
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark"> <!-- TODO: fix dataset link -->
                  <span class="icon">
                      <i class="fa-regular fa-database"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span>
              <!-- Model Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark"> <!-- TODO: fix model link -->
                  <span class="icon">
                    <i class="fa-solid fa-face-smiling-hands"></i>
                  </span>
                  <span>Model</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser -->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="subtitle has-text-centered">
        <img src="static/images/puffin.png"/>
        <span class="dnerf">Puffin-Zero</span> is an open reasoning language model that demonstrates the potential of
        large-scale RL training from pretrained checkpoints on solving competition-level math problems.
      </h2>
      <h2 class="subtitle has-text-centered">
        <img src="static/images/score.png"/>
        <span class="dnerf">Puffin-Zero</span> achieves 45.4 points on AIME 2024, a comparable performance to DeepSeek-R1-Zero-
        Qwen-32B.
      </h2>
    </div>
  </div>
</section> -->

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We introduce <span class="dnerf">Puffin-Zero</span>, a fully open-source language reasoning model trained with large-scale RL over Qwen2.5-32B base model, which achieves 45.4 points on AIME 2024, a comparable performance to DeepSeek-R1-Zero-Qwen-32B. Unlike previous works that withhold training details, we release the full algorithm details and open-source both training code and data, to facilitate future research on large-scale LLM RL. The entire training pipeline is implemented using <a href="https://github.com/volcengine/verl">verl</a>.
          </p>
        </div>
      </div>
    </div>

    <!-- Puffin Image -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="subtitle has-text-centered">
          <img src="static/images/puffin.png"/>
          <span class="dnerf">Puffin-Zero</span> is an open reasoning language model that demonstrates the potential of
          large-scale RL training from pretrained checkpoints on solving competition-level math problems.
        </h2>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Key Result -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Key Result</h2>
      </div>
    </div>

    <!-- Score -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="subtitle has-text-centered">
          <img src="static/images/score.png"/>
          <span class="dnerf">Puffin-Zero</span> is an open reasoning language model that demonstrates the potential of
          large-scale RL training from pretrained checkpoints on solving competition-level math problems.
        </h2>
      </div>
    </div>

    <!-- Length -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="subtitle has-text-centered">
          <img src="static/images/length.png"/>
          Some caption.
        </h2>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Fully Open-Source -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Fully Open-Source</h2>
        <div class="content has-text-justified">
          <p>
            To benefit the broader research community, we make fully open-source the recipe of our RL training, including algorithm details, dataset, verifiers, model weights and infrastructures. We hope our project could help the research community to unlock the secret of large-scale RL training much easier. We'll provide a detailed technical report soon.
          </p>
          <ul>
            <li>
              Infrastructure: We utilize <a href="https://github.com/volcengine/verl">verl</a> to perform GRPO training using the Qwen-32B-Base model from scratch with 128 H20 GPUs.
            </li>
            <li>
              Data: We provide training and evaluation datasets for <span class="dnerf">Puffin-Zero</span> training.
              <ul>
                <li>
                  Evaluation Dataset: AIME24 dataset.
                </li>
                <li>
                  Training Dataset: A meticulously processed math dataset. 
                </li>
              </ul>
            </li>
            <li>
              Verifiers: [Rule-based Verifier](link).
            </li>
            <li>
              Training Scripts: Elaborate hyper-parameters for reproduction.
            </li>
            <li>
              Model weights: Coming Soon (training still in progress). Currently, the best evaluation accuracy for AIME24 is 45.4%.
            </li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Algorithm Insights -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Algorithm Insights</h2>
        <div class="content has-text-justified">
          <p>
            Before we can present a comprehensive technical report in the near future, we conclude several key points that we discovered during the training process.
          </p>
          <ul>
            <li>
              Clip-Higher, which promotes the diversity of the system and avoids entropy collapse;
            </li>
          </ul>
          <p>
            We observe an entropy-collapsing phenomenon in our initial experiments. We propose increasing the upper clip range of the importance sampling ratio in policy gradient loss to mitigate this problem.
          </p>
          <ul>
            <li>
              Accuracy Filtering with Over-Sampling, which improves training efficiency and stability;
            </li>
          </ul>
          <p>
            During the training of GRPO, we find that the number of samples with accuracy equal to 1 increases continuously. To this end, we propose a strategy that over-samples and filters out groups with the accuracy equal to 1 and 0, leaving all prompts in the batch with effective gradients and keeping a consistent number of prompts.
          </p>
          <ul>
            <li>
              Token-level Policy Gradient Loss, which is critical in long-CoT RL scenarios;
            </li>
          </ul>
          <p>
            The original GRPO algorithm employs a sample-level loss calculation, which involves first averaging the losses by token within each sample and then aggregating the losses across samples. In this approach, each sample is assigned an equal weight in the final loss computation. However, we find that this method of loss reduction performs badly in the context of long-CoT RL scenarios. We adopt a Token-level Policy Gradient Loss.
          </p>
          <ul>
            <li>
              Overlong Reward Shaping, which reduces reward noise and stabilizes training.
            </li>
          </ul>
          <p>
            For overlong examples, we design a soft overlong punishment reward.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Datasets -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Datasets</h2>
        <div class="content has-text-justified">
          <p>
            The answers of math dataset typically come in a variety of formats, such as expression, formula and number, which makes it challenging to design comprehensive rules to parse them. To provide accurate reward signals using rules and minimize errors introduced by formula parsers, inspired by AIME, we select and transform the answers into integers, which are easy to parse. For example, if the original answer is expressed in the form of \( \frac{a + \sqrt{b}}{c} \), we instruct the LLM to modify the question so that the expected answer becomes \( a + b + c \). We also append corresponding instructions after the question in the prompt, guiding the model to generate answers in the desired format. After reformatting, we employ validation techniques (e.g. rejection sampling) to verify the correctness and usability of the modified problems. This processing ensures that the reformulated dataset maintains its validity and aligns with the intended evaluation criteria. Our final dataset consists of ~20K prompts.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Experiment Setting -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Experiment Setting</h2>
        <div class="content has-text-justified">
          <p>
            We utilize our training data to perform GRPO training on Qwen2.5-32B-Base without any cold start (i.e., supervised finetune). The model is trained on 16 H20 machines (128 H20 GPUs in total). Each machine is equipped with 8 NVIDIA H20-96GB GPUs inter-connected with xxx GB/s NVLink. The inter-machine bandwidth is xxGbps. Up till now (03/15/2025), the model has been trained for xxx GPU hours. We use <a href="https://github.com/volcengine/verl">verl</a> to perform training.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Contributions -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Contributions</h2>
        <div class="content has-text-justified">
          <p>
            
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>
        <div class="content has-text-justified">
          
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2> <!-- TODO -->
    <pre><code>@article{2025puffinzero,
  author    = {Author 1, Author 2, Author 3},
  title     = {Puffin-Zero},
  journal   = {Arxiv},
  year      = {2025},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href=""> <!-- TODO: fix pdf link -->
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="" class="external-link" disabled> <!-- TODO: fix home link -->
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is adapted from <a href="https://nerfies.github.io/">Nerfies</a> and licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
